{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import nltk,re,pprint\n",
    "import sys,glob,os\n",
    "import operator, string, argparse, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getallfilenames(foldername):#returns the name of all files inside the source folder. \t\t\n",
    "    owd = os.getcwd()\n",
    "    fld = foldername + \"/\"\n",
    "    os.chdir(fld)\t\t\t\t\t#this is the name of the folder from which the file names are returned.\n",
    "    fnamearr = []\t\t\t\t\t\t#empty array, the names of files are appended to this array, and returned.\n",
    "    for file in glob.glob(\"*.txt\"):\n",
    "        fnamearr.append(file)\n",
    "    os.chdir(owd)\n",
    "    return fnamearr\n",
    "\n",
    "def drawProgressBar(percent, barLen = 50):\t\t\t#just a progress bar so that you dont lose patience\n",
    "    sys.stdout.write(\"\\r\")2\n",
    "    progress = \"\"\n",
    "    for i in range(barLen):\n",
    "        if i<int(barLen * percent):\n",
    "            progress += \"=\"\n",
    "        else:\n",
    "            progress += \" \"\n",
    "    sys.stdout.write(\"[ %s ] %.2f%%\" % (progress, percent * 100))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "#allfnames = getallfilenames(\"/Users/arnabborah/Documents/repositories/textclusteringDBSCAN/processFiles/trainCatFiles\")\n",
    "#allfnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Job Description  Company Name\n",
      "Industry                                                       \n",
      "-1                                            353           352\n",
      "IT Services                                   325           325\n",
      "Staffing & Outsourcing                        323           323\n",
      "Health Care Services & Hospitals              151           151\n",
      "Consulting                                    111           111\n",
      "...                                           ...           ...\n",
      "Chemical Manufacturing                          1             1\n",
      "Pet & Pet Supplies Stores                       1             1\n",
      "Consumer Product Rental                         1             1\n",
      "Metals Brokers                                  1             1\n",
      "News Outlet                                     1             1\n",
      "\n",
      "[89 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "class dataProcessor:\n",
    "    def __init__(self, fname, keep_factors = ['Job Description', 'Company Name', 'Industry'], group_column = 'Industry'):\n",
    "        self.dataInitial = pd.read_csv(fname, encoding=\"latin\")\n",
    "        self.dataInitialSmall = self.dataInitial[['Job Description', 'Company Name', 'Industry']]\n",
    "        self.swords = set(stopwords.words('english'))\n",
    "        #print(len(self.swords),\"stopwords present!\")\n",
    "        self.dataInitialGrouped = self.dataInitialSmall.groupby([group_column]).count()\n",
    "        pd.set_option('display.max_rows', 50)\n",
    "        print(self.dataInitialGrouped.sort_values(by=['Job Description'], ascending=False))\n",
    "\n",
    "    # pipeline for purifying the text, write-pipeline, so just output filename can be provided\n",
    "    def rem_stop_punct(self,originalText, ofilename):\n",
    "        splittedText = originalText.split()\n",
    "        lenl = len(splittedText)\n",
    "        print(\"Length is: \",lenl, splittedText[:5])\n",
    "        ofile = open(ofilename,'a')\n",
    "        \n",
    "        for r in range(lenl):\n",
    "            linex = splittedText[r]\n",
    "            linex2 = \"\".join(c for c in linex if c not in ('!','.',':',',','?',';','``','&','-','\"','(',')','[',']','0','1','2','3','4','5','6','7','8','9'))\n",
    "            linex3 = linex2.split()\n",
    "            #prog=(r+1)/len(rawlines)\n",
    "            for s in range(len(linex3)):\n",
    "                noword = linex3[s].lower()\n",
    "                if noword not in self.swords:\n",
    "                    ofile.write(noword)\n",
    "                    ofile.write(\" \")\n",
    "                    \n",
    "os.chdir(\"/Users/arnabborah/Documents/repositories/textclusteringDBSCAN/scripts/\")\n",
    "\n",
    "# using both the classes declared above on a new dataset\n",
    "rp = dataProcessor(\"../datasets/DataAnalyst.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Job Description  \\\n",
      "0     Are you eager to roll up your sleeves and harn...   \n",
      "1     Overview\\n\\nProvides analytical and technical ...   \n",
      "2     Weâre looking for a Senior Data Analyst who ...   \n",
      "3     Requisition NumberRR-0001939\\nRemote:Yes\\nWe c...   \n",
      "4     ABOUT FANDUEL GROUP\\n\\nFanDuel Group is a worl...   \n",
      "...                                                 ...   \n",
      "2248  Maintains systems to protect data from unautho...   \n",
      "2249  Position:\\nSenior Data Analyst (Corporate Audi...   \n",
      "2250  Title: Technical Business Analyst (SQL, Data a...   \n",
      "2251  Summary\\n\\nResponsible for working cross-funct...   \n",
      "2252  You.\\n\\nYou bring your body, mind, heart and s...   \n",
      "\n",
      "                                 Company Name  \\\n",
      "0              Vera Institute of Justice\\n3.2   \n",
      "1     Visiting Nurse Service of New York\\n3.8   \n",
      "2                            Squarespace\\n3.4   \n",
      "3                               Celerity\\n4.1   \n",
      "4                                FanDuel\\n3.9   \n",
      "...                                       ...   \n",
      "2248                       Avacend, Inc.\\n2.5   \n",
      "2249                   Arrow Electronics\\n2.9   \n",
      "2250                                 Spiceorb   \n",
      "2251         Contingent Network Services\\n3.1   \n",
      "2252                          SCL Health\\n3.4   \n",
      "\n",
      "                                     Industry  \\\n",
      "0                           Social Assistance   \n",
      "1            Health Care Services & Hospitals   \n",
      "2                                    Internet   \n",
      "3                                 IT Services   \n",
      "4                         Sports & Recreation   \n",
      "...                                       ...   \n",
      "2248                   Staffing & Outsourcing   \n",
      "2249                                Wholesale   \n",
      "2250                                       -1   \n",
      "2251  Enterprise Software & Network Solutions   \n",
      "2252         Health Care Services & Hospitals   \n",
      "\n",
      "                                               tfMatrix  \n",
      "0          count           word\n",
      "0       59          ...  \n",
      "1          count         word\n",
      "0       51          an...  \n",
      "2          count         word\n",
      "0       35          an...  \n",
      "3          count       word\n",
      "0       44        and\n",
      "1 ...  \n",
      "4          count        word\n",
      "0       27         and\n",
      "...  \n",
      "...                                                 ...  \n",
      "2248      count        word\n",
      "0       4         and\n",
      "1 ...  \n",
      "2249       count                word\n",
      "0       38     ...  \n",
      "2250       count      word\n",
      "0       26       and\n",
      "1   ...  \n",
      "2251       count           word\n",
      "0       40          ...  \n",
      "2252       count     word\n",
      "0       28      and\n",
      "1     ...  \n",
      "\n",
      "[2253 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "class flingTFIDF:\n",
    "    def __init__(self,data,cname):\n",
    "        self.idfMatrix = {}\n",
    "        self.termsforIDF = []\n",
    "        self.cname = cname\n",
    "        self.data = data\n",
    "        \n",
    "    def getTF(self):\n",
    "        self.tfList = []\n",
    "        for index, row in self.data.iterrows():\n",
    "            words_in_column = row[self.cname].split()\n",
    "            counts_all = Counter(words_in_column)\n",
    "            words, count_values = zip(*counts_all.items())\n",
    "            values_sorted, words_sorted = zip(*sorted(zip(count_values, words), key=operator.itemgetter(0), reverse=True))\n",
    "            countdf = pd.DataFrame({'count': values_sorted, 'word': words_sorted})\n",
    "            self.tfList.append(countdf)\n",
    "        self.data['tfMatrix'] = self.tfList\n",
    "        print(self.data)\n",
    "        \n",
    "ftf = flingTFIDF(rp.dataInitialSmall,'Job Description')\n",
    "ftf.getTF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
